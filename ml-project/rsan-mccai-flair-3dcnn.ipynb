{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Computer Vision Approach"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T15:51:03.000647Z","iopub.status.busy":"2021-12-12T15:51:03.00035Z","iopub.status.idle":"2021-12-12T15:51:03.007814Z","shell.execute_reply":"2021-12-12T15:51:03.007057Z","shell.execute_reply.started":"2021-12-12T15:51:03.000613Z"},"trusted":true},"outputs":[],"source":["\n","import os                                   # Iterate over dataset directories\n","import numpy as np                          # Linear algebra\n","import pandas as pd                         # Data processing (read labels CSV)\n","import cv2 as cv\n","\n","# Opencv for image files\n","import pydicom                              # Read dcm files\n","from sklearn.cluster import MiniBatchKMeans # Create bag of visual words\n","from sklearn.svm import SVC                 # Classifier\n","import pickle                               # Serialize and save features extracted from dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T15:33:33.718785Z","iopub.status.busy":"2021-12-12T15:33:33.718077Z","iopub.status.idle":"2021-12-12T15:33:33.724386Z","shell.execute_reply":"2021-12-12T15:33:33.723631Z","shell.execute_reply.started":"2021-12-12T15:33:33.718745Z"},"trusted":true},"outputs":[],"source":["\n","def dcmToGray(dcm):\n","    image = dcm.pixel_array\n","    if np.amax(image) != 0:\n","        gray = np.uint8(image/np.amax(image)*255)\n","    else:\n","        gray = np.uint8(image)\n","    return gray"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T15:33:34.873035Z","iopub.status.busy":"2021-12-12T15:33:34.872561Z","iopub.status.idle":"2021-12-12T15:33:34.879236Z","shell.execute_reply":"2021-12-12T15:33:34.878472Z","shell.execute_reply.started":"2021-12-12T15:33:34.873Z"},"trusted":true},"outputs":[],"source":["train_path =  \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train\"\n","test_path  = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T15:33:35.921468Z","iopub.status.busy":"2021-12-12T15:33:35.920774Z","iopub.status.idle":"2021-12-12T15:33:35.925845Z","shell.execute_reply":"2021-12-12T15:33:35.924859Z","shell.execute_reply.started":"2021-12-12T15:33:35.921433Z"},"trusted":true},"outputs":[],"source":["subdirs = [\"/FLAIR\", \"/T1w\", \"/T1wCE\", \"/T2w\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T16:09:30.398631Z","iopub.status.busy":"2021-12-12T16:09:30.397876Z","iopub.status.idle":"2021-12-12T16:09:30.409688Z","shell.execute_reply":"2021-12-12T16:09:30.408908Z","shell.execute_reply.started":"2021-12-12T16:09:30.398581Z"},"trusted":true},"outputs":[],"source":["train_size = len(next(os.walk(train_path))[1])\n","test_size  = len(next(os.walk(test_path))[1])\n","descriptor_size = 32\n","\n","# Feature detector\n","detector = cv.ORB_create(64)\n","\n","# Size of visual vocabulary\n","vocab_size = 2000\n","\n","\n","# Feature detector\n","detector =  cv.ORB_create(64)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T16:09:34.158746Z","iopub.status.busy":"2021-12-12T16:09:34.158251Z","iopub.status.idle":"2021-12-12T16:09:34.163451Z","shell.execute_reply":"2021-12-12T16:09:34.162729Z","shell.execute_reply.started":"2021-12-12T16:09:34.158707Z"},"trusted":true},"outputs":[],"source":["curr_features = np.array([]).reshape(0,descriptor_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T16:10:22.222564Z","iopub.status.busy":"2021-12-12T16:10:22.22228Z","iopub.status.idle":"2021-12-12T16:10:22.23797Z","shell.execute_reply":"2021-12-12T16:10:22.237232Z","shell.execute_reply.started":"2021-12-12T16:10:22.222533Z"},"trusted":true},"outputs":[],"source":["dcm  = pydicom.dcmread(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/FLAIR/Image-101.dcm\")\n","gray = dcmToGray(dcm)\n","gray=cv.resize(gray, (512, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T16:10:53.074412Z","iopub.status.busy":"2021-12-12T16:10:53.073677Z","iopub.status.idle":"2021-12-12T16:10:53.087514Z","shell.execute_reply":"2021-12-12T16:10:53.086843Z","shell.execute_reply.started":"2021-12-12T16:10:53.07437Z"},"trusted":true},"outputs":[],"source":["keypoints, descriptors = detector.detectAndCompute(gray,None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T16:12:38.609859Z","iopub.status.busy":"2021-12-12T16:12:38.609541Z","iopub.status.idle":"2021-12-12T16:12:38.619441Z","shell.execute_reply":"2021-12-12T16:12:38.618515Z","shell.execute_reply.started":"2021-12-12T16:12:38.609817Z"},"trusted":true},"outputs":[],"source":["\n","train_size = len(next(os.walk(train_path))[1])\n","test_size  = len(next(os.walk(test_path))[1])\n","descriptor_size = 128\n","\n","# Feature detector\n","detector = cv.SIFT_create(400)\n","\n","# Size of visual vocabulary\n","vocab_size = 2000\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T16:12:46.903576Z","iopub.status.busy":"2021-12-12T16:12:46.902857Z"},"trusted":true},"outputs":[],"source":["\n","\n","# Populating array of visual features with the descriptors computed by the defined detector\n","\n","# Each element of this list is an array of all the descriptor arrays\n","# computed by the detector for every image of each sample.\n","features_per_sample = []\n","\n","i = 0\n","while(len(features_per_sample) < train_size):\n","    # Current directory\n","    curr_dir = train_path + '/{0:05d}'.format(i)\n","                                              \n","                                              \n","    \n","    i += 1\n","    \n","    # If the there is no such directory, continue to the next one\n","    if not os.path.exists(curr_dir):\n","        continue\n","        \n","    # Array of descriptor array for each image of current sample\n","    curr_features = np.array([]).reshape(0,descriptor_size)\n","        \n","    # Process the images from each subdirectory in the current dir\n","    for subdir in subdirs:\n","        curr_subdir = curr_dir+subdir\n","        for filename in os.listdir(curr_subdir):\n","            dcm  = pydicom.dcmread(curr_subdir+'/'+filename)\n","            gray = dcmToGray(dcm)\n","            gray=cv2.resize(gray, (512, 512))\n","            keypoints, descriptors = detector.detectAndCompute(gray,None)\n","            if descriptors is not None:\n","                curr_features = np.vstack([curr_features, descriptors])\n","                \n","    features_per_sample.append(curr_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["all_features = np.array([]).reshape(0,descriptor_size)\n","for sample_features in features_per_sample:\n","    all_features = np.vstack([all_features, sample_features])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["kmeans = MiniBatchKMeans(n_clusters = vocab_size,\n","                         batch_size = vocab_size//10,\n","                         verbose    = False, \n","                         init       = 'k-means++',\n","                         n_init     = 3,\n","                         max_iter   = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["vocab = kmeans.fit(all_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["histograms = []\n","for sample_features in features_per_sample:\n","    \n","    sample_hist = np.zeros(vocab_size)\n","    n_features  = sample_features.shape[0]\n","    \n","    visual_word_indexes = vocab.predict(sample_features)\n","    for index in visual_word_indexes:\n","        sample_hist[index] += 1/n_features\n","        \n","    histograms.append(sample_hist)\n","\n","X_train = np.array(histograms)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Test set\n","histograms = []\n","test_sample_ids = []\n","i = 0\n","while(len(histograms) < test_size):\n","    # Current directory\n","    curr_dir = test_path + '/{0:05d}'.format(i)\n","    \n","    i += 1\n","    \n","    # If the there is no such directory, continue to the next one\n","    if not os.path.exists(curr_dir):\n","        continue\n","        \n","    test_sample_ids.append('{0:05d}'.format(i-1))\n","        \n","    # Array of descriptor array for each image of current sample\n","    curr_features = np.array([]).reshape(0,descriptor_size)\n","        \n","    # Process the images from each subdirectory in the current dir\n","    for subdir in subdirs:\n","        curr_subdir = curr_dir+subdir\n","        for filename in os.listdir(curr_subdir):\n","            dcm  = pydicom.dcmread(curr_subdir+'/'+filename)\n","            gray = dcmToGray(dcm)\n","            keypoints, descriptors = detector.detectAndCompute(gray,None)\n","            if descriptors is not None:\n","                curr_features = np.vstack([curr_features, descriptors])\n","                \n","    sample_hist = np.zeros(vocab_size)\n","    n_features  = curr_features.shape[0]\n","    \n","    visual_word_indexes = vocab.predict(curr_features)\n","    for index in visual_word_indexes:\n","        sample_hist[index] += 1/n_features\n","        \n","    histograms.append(sample_hist)\n","    \n","X_test = np.array(histograms)\n","test_sample_ids = np.array(test_sample_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["labels = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\n","labels = labels.iloc[:,1].values\n","\n","train_labels = labels[0:int(0.9*train_size)]\n","valid_labels = labels[int(0.9*train_size):train_size]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_valid = X_train[int(0.9*train_size):train_size,:]\n","X_train = X_train[0:int(0.9*train_size),:]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svc = SVC(probability=True)\n","svc.fit(X_train, train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["score = svc.score(X_valid, valid_labels)\n","print(score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pred = svc.predict_proba(X_test)\n","print(pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame({\"Id\": list(range(0,len(preds))), \"Covtype\": preds}).to_csv(fname, index=False, header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def write_preds(fname):\n","    pd.DataFrame(X_train).to_csv(fname, index=False, header=True)\n","\n","write_preds(\"varun-predict-17.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import csv\n","\n","with open(\"out.csv\", \"w\", newline=\"\") as f:\n","    writer = csv.writer(f)\n","    writer.writerows(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import csv\n","\n","with open(\"out2.csv\", \"w\", newline=\"\") as f:\n","    writer = csv.writer(f)\n","    writer.writerows(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","x=pd.read_csv('out1.csv',header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.utils import np_utils\n","from keras.layers.core import Dense, Activation, Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report,confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["scaler=StandardScaler()\n","scaler.fit(X_train)\n","X_train=scaler.transform(X_train)\n","X_test=scaler.transform(X_test)\n","Y_train=np_utils.to_categorical(train_labels)\n","X_valid=scaler.transform(X_valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_dim = X_train.shape[1]\n","nb_classes = Y_train.shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = Sequential()\n","model.add(Dense(50, input_dim=input_dim))\n","model.add(Activation('softmax'))\n","\n","model.add(Dense(50, input_dim=input_dim))\n","model.add(Activation('softmax'))\n","\n","\n","\n","\n","model.add(Dense(nb_classes))\n","model.add(Activation('softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', optimizer='adam')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Training...\")\n","\n","model.fit(X_train, Y_train, epochs=100,batch_size=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Generating test predictions...\")\n","predict_x=model.predict(X_train) \n","classes_x=np.argmax(predict_x,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(classification_report(train_labels,classes_x))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T16:48:42.558048Z","iopub.status.busy":"2021-12-04T16:48:42.557213Z","iopub.status.idle":"2021-12-04T16:48:42.584099Z","shell.execute_reply":"2021-12-04T16:48:42.582652Z","shell.execute_reply.started":"2021-12-04T16:48:42.558002Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T16:49:18.468901Z","iopub.status.busy":"2021-12-04T16:49:18.468374Z","iopub.status.idle":"2021-12-04T16:49:21.274604Z","shell.execute_reply":"2021-12-04T16:49:21.273568Z","shell.execute_reply.started":"2021-12-04T16:49:18.468869Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-04T17:35:09.914298Z","iopub.status.busy":"2021-12-04T17:35:09.914023Z","iopub.status.idle":"2021-12-04T17:37:11.861336Z","shell.execute_reply":"2021-12-04T17:37:11.860183Z","shell.execute_reply.started":"2021-12-04T17:35:09.914268Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# 3d CNN model "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-05T03:58:39.920619Z","iopub.status.busy":"2021-12-05T03:58:39.920217Z","iopub.status.idle":"2021-12-05T03:58:42.237259Z","shell.execute_reply":"2021-12-05T03:58:42.236533Z","shell.execute_reply.started":"2021-12-05T03:58:39.920585Z"},"trusted":true},"outputs":[],"source":["from keras.models import Sequential\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n","from keras import optimizers, losses, activations, models\n","from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n","from keras import applications\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T19:52:42.150425Z","iopub.status.busy":"2021-12-12T19:52:42.150148Z","iopub.status.idle":"2021-12-12T19:52:42.160716Z","shell.execute_reply":"2021-12-12T19:52:42.159784Z","shell.execute_reply.started":"2021-12-12T19:52:42.150378Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import os\n","import glob\n","import re\n","import cv2\n","\n","import pydicom\n","from pydicom.pixel_data_handlers.util import apply_voi_lut\n","\n","from matplotlib import pyplot as plt\n","import math\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling3D,MaxPool3D,MaxPooling3D,AveragePooling3D,Dense, Flatten, Dropout, GlobalAveragePooling2D, Flatten, BatchNormalization, Conv3D\n","from random import shuffle\n","from sklearn.model_selection import train_test_split\n","\n","from keras import backend as K\n","from textwrap import wrap"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T19:52:42.558393Z","iopub.status.busy":"2021-12-12T19:52:42.558110Z","iopub.status.idle":"2021-12-12T19:52:42.563847Z","shell.execute_reply":"2021-12-12T19:52:42.562513Z","shell.execute_reply.started":"2021-12-12T19:52:42.558363Z"},"trusted":true},"outputs":[],"source":["import os\n","import zipfile\n","import numpy as np\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T19:52:33.143853Z","iopub.status.busy":"2021-12-12T19:52:33.143277Z","iopub.status.idle":"2021-12-12T19:52:33.185047Z","shell.execute_reply":"2021-12-12T19:52:33.184289Z","shell.execute_reply.started":"2021-12-12T19:52:33.143809Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\n","testSub = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\n","df['BraTS21ID5'] = [format(x, '05d') for x in df.BraTS21ID]\n","data_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\n","train_folder = os.path.join(data_path, 'train')\n","df['imfolder'] = ['{:05d}'.format(s) for s in df['BraTS21ID']]\n","df['path'] = [os.path.join(train_folder, s) for s in df['imfolder']]\n","\n","#Drop these four samples sice organizers pointed out they were not valid:\n","df.drop(df.index[df['BraTS21ID5'] == \"00109\"], inplace = True)\n","df.drop(df.index[df['BraTS21ID5'] == \"00123\"], inplace = True)\n","df.drop(df.index[df['BraTS21ID5'] == \"00709\"], inplace = True)\n","\n","\n","#Split into train and test set:\n","train_df, test_df = train_test_split(df, test_size=0.20)\n","train_df.iloc[0:5]"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:28:23.732375Z","iopub.status.busy":"2021-12-12T21:28:23.732120Z","iopub.status.idle":"2021-12-12T21:28:23.740778Z","shell.execute_reply":"2021-12-12T21:28:23.740084Z","shell.execute_reply.started":"2021-12-12T21:28:23.732345Z"},"trusted":true},"outputs":[],"source":["def loadimage(path, img_size=128):\n","    dicom_image=dcmread(path)\n","#     dicom = pydicom.read_file(path)\n","#     data = dicom.pixel_array\n","#     data = cv2.resize(data, (img_size, img_size))\n","    pixel_array = dicom_image.pixel_array[80:400, 100:420]\n","    if np.max(pixel_array) == 0:#Blank image\n","        return []\n","    else:    \n","        pixel_array = cv2.resize(pixel_array, (img_size, img_size))\n","        pixel_array = np.array(pixel_array, dtype = float)\n","        pixel_array /= 4095\n","    return pixel_array"]},{"cell_type":"code","execution_count":164,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:28:24.387191Z","iopub.status.busy":"2021-12-12T21:28:24.386922Z","iopub.status.idle":"2021-12-12T21:28:24.396843Z","shell.execute_reply":"2021-12-12T21:28:24.395573Z","shell.execute_reply.started":"2021-12-12T21:28:24.387162Z"},"trusted":true},"outputs":[],"source":["def loadimages(scan_id, mtype=\"FLAIR\", split=\"train\"):\n","\n","    files = sorted(glob.glob(f\"{data_path}/{split}/{scan_id}/{mtype}/*.dcm\"), \n","       key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n","    images=[]\n","    \n","#     if scan_id in pick_idx: \n","#         #print('happens')\n","#         img_out = np.stack([load_dicom_image(f, rotate_img=rotate_img) for f in [files[kk] for kk in pick_idx[scan_id]]]).T    \n","#     else:\n","\n","    for f in files:\n","            if len(images)==0:\n","                images = np.expand_dims(loadimage(f),-1)\n","            else:\n","                if(len(loadimage(f))==0):\n","                    pass\n","                else:\n","                    images = np.append(images,np.expand_dims(loadimage(f),-1),axis=-1)\n","    images=np.nan_to_num(images)\n","    try:\n","        images=images[:,:,np.linspace(0,24,24,dtype=int)]\n","        output = np.array(images,dtype=float)\n","        return(output)\n","        \n","    except:\n","        return []\n","        \n","    \n","        \n","    \n","    \n","    "]},{"cell_type":"code","execution_count":165,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:28:31.583247Z","iopub.status.busy":"2021-12-12T21:28:31.582907Z","iopub.status.idle":"2021-12-12T21:41:07.691063Z","shell.execute_reply":"2021-12-12T21:41:07.690131Z","shell.execute_reply.started":"2021-12-12T21:28:31.583208Z"},"trusted":true},"outputs":[],"source":["X_train=[]\n","Y_train=[]\n","z=train_df[\"MGMT_value\"].values\n","u=train_df['BraTS21ID5'].values\n","for i in range(len(u)):\n","    x=loadimages(u[i], mtype=\"FLAIR\", split=\"train\")\n","    if(len(x)!=0):\n","        X_train.append(x)\n","        Y_train.append(z[i])\n","        print(i)"]},{"cell_type":"code","execution_count":166,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:42:22.025582Z","iopub.status.busy":"2021-12-12T21:42:22.025177Z","iopub.status.idle":"2021-12-12T21:44:41.919555Z","shell.execute_reply":"2021-12-12T21:44:41.918827Z","shell.execute_reply.started":"2021-12-12T21:42:22.025542Z"},"trusted":true},"outputs":[],"source":["X_valid=[]\n","Y_valid=[]\n","z=test_df[\"MGMT_value\"].values\n","u=test_df['BraTS21ID5'].values\n","for i in range(len(u)):\n","    x=loadimages(u[i], mtype=\"FLAIR\", split=\"train\")\n","    if(len(x)!=0):\n","        X_valid.append(x)\n","        Y_valid.append(z[i])\n","        print(i)"]},{"cell_type":"code","execution_count":175,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:49:37.199353Z","iopub.status.busy":"2021-12-12T21:49:37.198864Z","iopub.status.idle":"2021-12-12T21:49:38.679675Z","shell.execute_reply":"2021-12-12T21:49:38.678633Z","shell.execute_reply.started":"2021-12-12T21:49:37.199313Z"},"trusted":true},"outputs":[],"source":["X_train=np.array(X_train)\n","Y_train=np.array(Y_train)\n","X_valid=np.array(X_valid)\n","Y_valid=np.array(Y_valid)"]},{"cell_type":"code","execution_count":161,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:27:47.661117Z","iopub.status.busy":"2021-12-12T21:27:47.660825Z","iopub.status.idle":"2021-12-12T21:27:47.665580Z","shell.execute_reply":"2021-12-12T21:27:47.664105Z","shell.execute_reply.started":"2021-12-12T21:27:47.661084Z"},"trusted":true},"outputs":[],"source":["# X_train=[]\n","# Y_train=[]\n","# z=train_df[\"MGMT_value\"].values\n","# u=train_df['BraTS21ID5'].values\n","# for i in range(len(u)):\n","#     x=loadimages(u[i], mtype=\"T1wCE\", split=\"train\")\n","#     if(len(x)!=0):\n","#         X_train.append(x)\n","#         Y_train.append(z[i])\n","#         print(i)"]},{"cell_type":"code","execution_count":162,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:27:58.501918Z","iopub.status.busy":"2021-12-12T21:27:58.501486Z","iopub.status.idle":"2021-12-12T21:27:58.508649Z","shell.execute_reply":"2021-12-12T21:27:58.507945Z","shell.execute_reply.started":"2021-12-12T21:27:58.501879Z"},"trusted":true},"outputs":[],"source":["# X_valid=[]\n","# Y_valid=[]\n","# z=test_df[\"MGMT_value\"].values\n","# u=test_df['BraTS21ID5'].values\n","# for i in range(len(u)):\n","#     x=loadimages(u[i], mtype=\"T1wCE\", split=\"train\")\n","#     if(len(x)!=0):\n","#         X_valid.append(x)\n","#         Y_valid.append(z[i])\n","#         print(i)"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T20:35:15.440045Z","iopub.status.busy":"2021-12-12T20:35:15.439507Z","iopub.status.idle":"2021-12-12T20:35:17.318540Z","shell.execute_reply":"2021-12-12T20:35:17.317693Z","shell.execute_reply.started":"2021-12-12T20:35:15.440005Z"},"trusted":true},"outputs":[],"source":["# X_train=np.array(X_train)\n","# Y_train=np.array(Y_train)\n","# X_valid=np.array(X_valid)\n","# Y_valid=np.array(Y_valid)"]},{"cell_type":"code","execution_count":172,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:48:54.822606Z","iopub.status.busy":"2021-12-12T21:48:54.822324Z","iopub.status.idle":"2021-12-12T21:48:54.831946Z","shell.execute_reply":"2021-12-12T21:48:54.831280Z","shell.execute_reply.started":"2021-12-12T21:48:54.822576Z"},"trusted":true},"outputs":[],"source":["def get_model(width=128, height=128, depth=24):\n","    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n","\n","    inputs = keras.Input((width, height, depth, 1))\n","\n","    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dropout(0.1)(x)   \n","    x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","    x = layers.BatchNormalization()(x)\n","    \n","    x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","    x = layers.GlobalAveragePooling3D()(x)\n","    x = layers.Dropout(0.1)(x)\n","    x = layers.Dense(units=512, activation=\"relu\")(x)\n","\n","    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n","\n","    # Define the model.\n","    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n","    return model"]},{"cell_type":"code","execution_count":177,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:51:35.889064Z","iopub.status.busy":"2021-12-12T21:51:35.888327Z","iopub.status.idle":"2021-12-12T21:51:35.963284Z","shell.execute_reply":"2021-12-12T21:51:35.962547Z","shell.execute_reply.started":"2021-12-12T21:51:35.889021Z"},"trusted":true},"outputs":[],"source":["model = get_model(width=128, height=128, depth=24)\n","model.summary()"]},{"cell_type":"code","execution_count":178,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T21:51:41.741982Z","iopub.status.busy":"2021-12-12T21:51:41.741725Z","iopub.status.idle":"2021-12-12T22:06:06.274989Z","shell.execute_reply":"2021-12-12T22:06:06.274201Z","shell.execute_reply.started":"2021-12-12T21:51:41.741953Z"},"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","    metrics=[AUC(name='auc'),\"acc\"],\n",")\n","epochs = 100\n","gc.collect()\n","model.fit(\n","    X_train,\n","    Y_train,\n","    batch_size=10,\n","    validation_data=(X_valid, Y_valid),\n","    epochs=epochs,\n","    shuffle=True,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Model prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T07:01:48.701426Z","iopub.status.busy":"2021-12-12T07:01:48.700877Z","iopub.status.idle":"2021-12-12T07:01:48.851886Z","shell.execute_reply":"2021-12-12T07:01:48.85115Z","shell.execute_reply.started":"2021-12-12T07:01:48.701387Z"},"trusted":true},"outputs":[],"source":["# Load best weights.\n","#model.load_weights(\"3d_image_classification.h5\")\n","prediction = model.predict(np.expand_dims(X_valid, axis=0))[0]\n","scores = [1 - prediction[0], prediction[0]]\n","\n","class_names = [\"tumor is absent\", \"tumor is present\"]\n","for score, name in zip(scores, class_names):\n","    print(\n","        \"This model is %.2f percent confident that  %s\"\n","        % ((100 * score), name)\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["# Compute the roc curve "]},{"cell_type":"code","execution_count":181,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T22:06:29.497117Z","iopub.status.busy":"2021-12-12T22:06:29.496852Z","iopub.status.idle":"2021-12-12T22:06:30.302669Z","shell.execute_reply":"2021-12-12T22:06:30.301933Z","shell.execute_reply.started":"2021-12-12T22:06:29.497087Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve,roc_auc_score\n","\n","fpr , tpr , thresholds = roc_curve ( Y_valid , model.predict(X_valid))"]},{"cell_type":"markdown","metadata":{},"source":["# Compute the f1 score of the model"]},{"cell_type":"code","execution_count":186,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T22:07:32.984786Z","iopub.status.busy":"2021-12-12T22:07:32.984246Z","iopub.status.idle":"2021-12-12T22:07:32.991360Z","shell.execute_reply":"2021-12-12T22:07:32.988826Z","shell.execute_reply.started":"2021-12-12T22:07:32.984745Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score\n","l=[]\n","for i in pred:\n","    if(i[0]>0.5):\n","        l.append(1)\n","    else:\n","        l.append(0)"]},{"cell_type":"code","execution_count":187,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T22:07:34.818597Z","iopub.status.busy":"2021-12-12T22:07:34.817934Z","iopub.status.idle":"2021-12-12T22:07:34.823500Z","shell.execute_reply":"2021-12-12T22:07:34.822466Z","shell.execute_reply.started":"2021-12-12T22:07:34.818557Z"},"trusted":true},"outputs":[],"source":["f1_score(Y_valid, l, average='macro')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
